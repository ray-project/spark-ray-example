{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call a Ray-based Web Servce from a PySpark UDF\n",
    "\n",
    "For completeness, this notebook demonstrates a more conventional alternative approach, having the PySpark UDF make a remote call to another service explicitly. This is conceptually simpler and has advantages in production; it may be easier to manage the processes separately. See also the discussion in [Spark-RayUDF.ipynb](Spark-RayUDF.ipynb), the notebook used in my Spark + AI Summit 2020 talk.\n",
    "\n",
    "You can learn more about Ray [here](http://ray.io).\n",
    "\n",
    "[Dean Wampler](mailto:dean@anyscale.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Requires Java 8!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java version \"1.8.0_221\"\n",
      "Java(TM) SE Runtime Environment (build 1.8.0_221-b11)\n",
      "Java HotSpot(TM) 64-Bit Server VM (build 25.221-b11, mixed mode)\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pyspark\n",
    "import ray\n",
    "from ray.util import named_actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DataType, BooleanType, NullType, IntegerType, StringType, MapType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a `DataGovernanceSystem` Ray actor that represents our governance system. All it does is add each reported id to an internal collection. A more realistic implementation would forward the ids, along with other useful metadata, asynchronously to a real governance system, like [Apache Atlas](http://atlas.apache.org/#/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class DataGovernanceSystem:\n",
    "    def __init__(self, name = 'DataGovernanceSystem'):\n",
    "        self.name = name\n",
    "        self.ids = []\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def log(self, id_to_log):\n",
    "        \"\"\"\n",
    "        Log record ids that have been processed.\n",
    "        Simulate an expensive operation by sleeping for 0.1 seconds\n",
    "        \"\"\"\n",
    "        time.sleep(0.1)\n",
    "        self.ids.append(id_to_log)\n",
    "\n",
    "    def get_ids(self):\n",
    "        \"\"\"Return the ids logged. Don't call this if the list is long!\"\"\"\n",
    "        return self.ids\n",
    "\n",
    "    def get_count(self):\n",
    "        \"\"\"Return the count of ids logged.\"\"\"\n",
    "        return len(self.ids)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Forget all ids that have been logged.\"\"\"\n",
    "        self.ids = []\n",
    "\n",
    "    def get_start_time(self):\n",
    "        return self.start_time\n",
    "\n",
    "    def get_up_time(self):\n",
    "        return time.time() - self.start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a simple `Record` type with a `record_id` field, used for logging to `DataGovernanceSystem`, and an opaque `data` field with everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Record:\n",
    "    def __init__(self, record_id, data):\n",
    "        self.record_id = record_id\n",
    "        self.data = data\n",
    "    def __str__(self):\n",
    "        return f'Record(record_id={self.record_id},data={self.data})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now initialize Ray. The `address='auto'` tells Ray to connect to a running cluster, where this node is part of that cluster, so Ray can find what it needs locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-16 12:01:02,757\tWARNING worker.py:809 -- When connecting to an existing cluster, _internal_config must match the cluster's _internal_config.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.149',\n",
       " 'raylet_ip_address': '192.168.1.149',\n",
       " 'redis_address': '192.168.1.149:14668',\n",
       " 'object_store_address': '/tmp/ray/session_2020-05-16_12-00-17_506849_39838/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-05-16_12-00-17_506849_39838/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-05-16_12-00-17_506849_39838'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(address='auto', ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click here to open the Ray Dashboard: http://localhost:8265\n"
     ]
    }
   ],
   "source": [
    "print(f'Click here to open the Ray Dashboard: http://{ray.get_webui_url()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(DataGovernanceSystem, 45b95b1c0100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_name = 'dgs'\n",
    "gov = DataGovernanceSystem.remote(actor_name)\n",
    "named_actors.register_actor(actor_name, gov)\n",
    "gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record(record_id=0,data=data: 0)\n",
      "Record(record_id=1,data=data: 1)\n",
      "Record(record_id=2,data=data: 2)\n"
     ]
    }
   ],
   "source": [
    "test_records = [Record(i, f'data: {i}') for i in range(3)] \n",
    "for record in test_records:\n",
    "    print(record)\n",
    "    gov.log.remote(record.record_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gov_status():\n",
    "    gov = named_actors.get_actor(name='dgs')\n",
    "    print(f'count:   {ray.get(gov.get_count.remote())}')\n",
    "    print(f'ids:     {ray.get(gov.get_ids.remote())}')\n",
    "    print(f'up time: {ray.get(gov.get_up_time.remote())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:   3\n",
      "ids:     [0, 1, 2]\n",
      "up time: 5.274358034133911\n"
     ]
    }
   ],
   "source": [
    "gov_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:   0\n",
      "ids:     []\n",
      "up time: 11.258324146270752\n"
     ]
    }
   ],
   "source": [
    "gov.reset.remote()\n",
    "gov_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def ray_log_record(id):\n",
    "    from ray.util import named_actors\n",
    "    gov = named_actors.get_actor(name='dgs')\n",
    "    gov.log.remote(id)   # Will run asynchronously, returning a future.\n",
    "    count = ray.get(gov.get_count.remote())  # but this blocks!\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_record(id):\n",
    "    \"\"\"\n",
    "    This function will become a UDF for Spark. Since each Spark task runs in a separate process, \n",
    "    we'll initialize Ray, connecting to the running cluster, if it is not already initialized.\n",
    "    \"\"\"\n",
    "    did_initialization = 0\n",
    "    if not ray.is_initialized():\n",
    "        ray.init(address='auto', redis_password='5241590000000000')\n",
    "        did_initialization = 1\n",
    "    count = ray.get(ray_log_record.remote(id))\n",
    "    return {'initialized': did_initialization, 'count': count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Data Governance Example\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_record_udf = udf(lambda id: log_record(id), MapType(StringType(), IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_records=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [Record(i, f'str: {i}') for i in range(num_records)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(records, ['id', 'data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ray = df.select('id', 'data', log_record_udf('id').alias('logged'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, data: bigint, logged: map<string,int>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_ray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------------------------------+\n",
      "|id     |data|logged                         |\n",
      "+-------+----+-------------------------------+\n",
      "|str: 0 |0   |[count -> 1, initialized -> 1] |\n",
      "|str: 1 |1   |[count -> 2, initialized -> 0] |\n",
      "|str: 2 |2   |[count -> 3, initialized -> 0] |\n",
      "|str: 3 |3   |[count -> 4, initialized -> 0] |\n",
      "|str: 4 |4   |[count -> 5, initialized -> 0] |\n",
      "|str: 5 |5   |[count -> 6, initialized -> 0] |\n",
      "|str: 6 |6   |[count -> 14, initialized -> 1]|\n",
      "|str: 7 |7   |[count -> 17, initialized -> 0]|\n",
      "|str: 8 |8   |[count -> 20, initialized -> 0]|\n",
      "|str: 9 |9   |[count -> 23, initialized -> 0]|\n",
      "|str: 10|10  |[count -> 26, initialized -> 0]|\n",
      "|str: 11|11  |[count -> 29, initialized -> 0]|\n",
      "|str: 12|12  |[count -> 13, initialized -> 1]|\n",
      "|str: 13|13  |[count -> 16, initialized -> 0]|\n",
      "|str: 14|14  |[count -> 19, initialized -> 0]|\n",
      "|str: 15|15  |[count -> 22, initialized -> 0]|\n",
      "|str: 16|16  |[count -> 25, initialized -> 0]|\n",
      "|str: 17|17  |[count -> 28, initialized -> 0]|\n",
      "|str: 18|18  |[count -> 15, initialized -> 1]|\n",
      "|str: 19|19  |[count -> 18, initialized -> 0]|\n",
      "|str: 20|20  |[count -> 21, initialized -> 0]|\n",
      "|str: 21|21  |[count -> 24, initialized -> 0]|\n",
      "|str: 22|22  |[count -> 27, initialized -> 0]|\n",
      "|str: 23|23  |[count -> 30, initialized -> 0]|\n",
      "|str: 24|24  |[count -> 7, initialized -> 0] |\n",
      "|str: 25|25  |[count -> 8, initialized -> 0] |\n",
      "|str: 26|26  |[count -> 9, initialized -> 0] |\n",
      "|str: 27|27  |[count -> 10, initialized -> 0]|\n",
      "|str: 28|28  |[count -> 11, initialized -> 0]|\n",
      "|str: 29|29  |[count -> 12, initialized -> 0]|\n",
      "|str: 30|30  |[count -> 31, initialized -> 0]|\n",
      "|str: 31|31  |[count -> 34, initialized -> 0]|\n",
      "|str: 32|32  |[count -> 37, initialized -> 0]|\n",
      "|str: 33|33  |[count -> 40, initialized -> 0]|\n",
      "|str: 34|34  |[count -> 43, initialized -> 0]|\n",
      "|str: 35|35  |[count -> 46, initialized -> 0]|\n",
      "|str: 36|36  |[count -> 32, initialized -> 0]|\n",
      "|str: 37|37  |[count -> 35, initialized -> 0]|\n",
      "|str: 38|38  |[count -> 38, initialized -> 0]|\n",
      "|str: 39|39  |[count -> 41, initialized -> 0]|\n",
      "|str: 40|40  |[count -> 44, initialized -> 0]|\n",
      "|str: 41|41  |[count -> 47, initialized -> 0]|\n",
      "|str: 42|42  |[count -> 33, initialized -> 0]|\n",
      "|str: 43|43  |[count -> 36, initialized -> 0]|\n",
      "|str: 44|44  |[count -> 39, initialized -> 0]|\n",
      "|str: 45|45  |[count -> 42, initialized -> 0]|\n",
      "|str: 46|46  |[count -> 45, initialized -> 0]|\n",
      "|str: 47|47  |[count -> 48, initialized -> 0]|\n",
      "|str: 48|48  |[count -> 49, initialized -> 0]|\n",
      "|str: 49|49  |[count -> 50, initialized -> 0]|\n",
      "+-------+----+-------------------------------+\n",
      "\n",
      "CPU times: user 237 ms, sys: 94.5 ms, total: 332 ms\n",
      "Wall time: 7.27 s\n"
     ]
    }
   ],
   "source": [
    "%time df_ray.show(n=num_records, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:   50\n",
      "ids:     ['str: 0', 'str: 1', 'str: 2', 'str: 3', 'str: 4', 'str: 5', 'str: 24', 'str: 25', 'str: 26', 'str: 27', 'str: 28', 'str: 29', 'str: 12', 'str: 6', 'str: 18', 'str: 13', 'str: 7', 'str: 19', 'str: 14', 'str: 8', 'str: 20', 'str: 15', 'str: 9', 'str: 21', 'str: 16', 'str: 10', 'str: 22', 'str: 17', 'str: 11', 'str: 23', 'str: 30', 'str: 36', 'str: 42', 'str: 31', 'str: 37', 'str: 43', 'str: 32', 'str: 38', 'str: 44', 'str: 33', 'str: 39', 'str: 45', 'str: 34', 'str: 40', 'str: 46', 'str: 35', 'str: 41', 'str: 47', 'str: 48', 'str: 49']\n",
      "up time: 57.627371072769165\n",
      "\u001b[2m\u001b[36m(pid=39848)\u001b[0m 2020-05-16 12:10:34,686\tINFO master.py:122 -- Starting router with name 'SERVE_ROUTER_ACTOR'\n",
      "\u001b[2m\u001b[36m(pid=39848)\u001b[0m 2020-05-16 12:10:34,689\tINFO master.py:143 -- Starting HTTP proxy with name 'SERVE_PROXY_ACTOR'\n",
      "\u001b[2m\u001b[36m(pid=39848)\u001b[0m 2020-05-16 12:10:34,693\tINFO master.py:168 -- Starting metric monitor with name 'SERVE_METRIC_MONITOR_ACTOR'\n",
      "\u001b[2m\u001b[36m(pid=39848)\u001b[0m 2020-05-16 12:10:34,707\tINFO master.py:483 -- Registering route /log to endpoint log with methods ['PUT'].\n",
      "\u001b[2m\u001b[36m(pid=39853)\u001b[0m INFO:     Started server process [39853]\n",
      "\u001b[2m\u001b[36m(pid=39853)\u001b[0m INFO:     Waiting for application startup.\n",
      "\u001b[2m\u001b[36m(pid=39853)\u001b[0m INFO:     Application startup complete.\n",
      "\u001b[2m\u001b[36m(pid=39848)\u001b[0m 2020-05-16 12:10:35,965\tINFO master.py:483 -- Registering route /ids to endpoint ids with methods ['GET'].\n",
      "\u001b[2m\u001b[36m(pid=39848)\u001b[0m 2020-05-16 12:10:35,999\tINFO master.py:483 -- Registering route /count to endpoint count with methods ['GET'].\n",
      "\u001b[2m\u001b[36m(pid=39848)\u001b[0m 2020-05-16 12:10:36,035\tINFO master.py:483 -- Registering route /reset to endpoint reset with methods ['PUT', 'GET'].\n",
      "\u001b[2m\u001b[36m(pid=39848)\u001b[0m 2020-05-16 12:10:36,077\tINFO master.py:483 -- Registering route /start_time to endpoint start_time with methods ['PUT', 'GET', 'POST'].\n",
      "\u001b[2m\u001b[36m(pid=39848)\u001b[0m 2020-05-16 12:10:36,354\tINFO master.py:483 -- Registering route /up_time to endpoint up_time with methods ['PUT', 'GET', 'POST'].\n",
      "\u001b[2m\u001b[36m(pid=39848)\u001b[0m 2020-05-16 12:10:36,397\tINFO master.py:483 -- Registering route /exit to endpoint exit with methods ['PUT', 'GET', 'POST'].\n",
      "\u001b[2m\u001b[36m(pid=39848)\u001b[0m E0516 12:10:38.655058 5341184 task_manager.cc:288] 3 retries left for task e6b7883868af38dbffffffff0800, attempting to resubmit.\n",
      "\u001b[2m\u001b[36m(pid=39848)\u001b[0m E0516 12:10:38.656335 5341184 core_worker.cc:373] Will resubmit task after a 5000ms delay: Type=NORMAL_TASK, Language=PYTHON, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.serve.metric, class_name=, function_name=start_metric_monitor_loop, function_hash=0ca6d5a847c8c2b1eaa78bc04d84c82a31644aa8}, task_id=e6b7883868af38dbffffffff0800, job_id=0800, num_args=2, num_returns=1\n",
      "\u001b[2m\u001b[36m(pid=40394)\u001b[0m 2020-05-16 12:10:38,653\tERROR worker.py:421 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=40394)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=40394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 531, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=40394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 419, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=40394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 459, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=40394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 462, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=40394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 463, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=40394)\u001b[0m   File \"/Users/deanwampler/anaconda3/envs/spark/lib/python3.7/site-packages/ray/serve/metric.py\", line 153, in start_metric_monitor_loop\n",
      "\u001b[2m\u001b[36m(pid=40394)\u001b[0m     time.sleep(duration_s)\n",
      "\u001b[2m\u001b[36m(pid=40394)\u001b[0m   File \"/Users/deanwampler/anaconda3/envs/spark/lib/python3.7/site-packages/ray/worker.py\", line 418, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=40394)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=40394)\u001b[0m SystemExit: 1\n"
     ]
    }
   ],
   "source": [
    "gov_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
