{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call a Ray-based Web Servce from a PySpark UDF\n",
    "\n",
    "For completeness, this notebook demonstrates a more conventional alternative approach, having the PySpark UDF make a remote call to another service explicitly. This is conceptually simpler and has advantages in production; it may be easier to manage the processes separately. See also the discussion in [Spark-RayUDF.ipynb](../Spark-RayUDF.ipynb), the notebook used in my Spark + AI Summit 2020 talk.\n",
    "\n",
    "> **Note:** Run all the cells in the [DataGovernanceServer.ipynb](DataGovernanceServer.ipynb) notebook **before** running this notebook.\n",
    "\n",
    "To learn more about Ray:\n",
    "* [Ray.io](http://ray.io)\n",
    "* [Ray Serve](https://docs.ray.io/en/master/rayserve/overview.html)\n",
    "\n",
    "[Dean Wampler](mailto:dean@anyscale.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Requires Java 8!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java version \"1.8.0_221\"\n",
      "Java(TM) SE Runtime Environment (build 1.8.0_221-b11)\n",
      "Java HotSpot(TM) 64-Bit Server VM (build 25.221-b11, mixed mode)\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests\n",
    "import pyspark\n",
    "import ray\n",
    "from ray.util import named_actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DataType, BooleanType, NullType, IntegerType, StringType, MapType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a simple `Record` type with a `record_id` field, used for logging to `DataGovernanceSystem`, and an opaque `data` field with everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Record:\n",
    "    def __init__(self, record_id, data):\n",
    "        self.record_id = record_id\n",
    "        self.data = data\n",
    "    def __str__(self):\n",
    "        return f'Record(record_id={self.record_id},data={self.data})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "port = 8100\n",
    "address = f'http://localhost:{port}'\n",
    "timeout = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record(record_id=0,data=data: 0)\n",
      "log response = {'message': 'sent async log request for 0'}\n",
      "Record(record_id=1,data=data: 1)\n",
      "log response = {'message': 'sent async log request for 1'}\n",
      "Record(record_id=2,data=data: 2)\n",
      "log response = {'message': 'sent async log request for 2'}\n"
     ]
    }
   ],
   "source": [
    "test_records = [Record(i, f'data: {i}') for i in range(3)] \n",
    "for record in test_records:\n",
    "    print(record)\n",
    "    response = requests.put(f'{address}/log?id={record.record_id}', timeout=timeout)\n",
    "    print(f'log response = {response.json()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gov_status():\n",
    "    count = requests.get(f'{address}/count', timeout=timeout)\n",
    "    print(f'count:    {count.json()}')\n",
    "    ids = requests.get(f'{address}/ids', timeout=timeout)\n",
    "    print(f'ids:      {ids.json()}')\n",
    "    up_time = requests.get(f'{address}/up_time', timeout=timeout)\n",
    "    print(f'up time:  {up_time.json()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:    {'count': 3}\n",
      "ids:      {'ids': ['0', '1', '2']}\n",
      "up time:  {'up_time': 620.9878726005554}\n"
     ]
    }
   ],
   "source": [
    "gov_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.put(f'http://127.0.0.1:{port}/reset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:    {'count': 0}\n",
      "ids:      {'ids': []}\n",
      "up time:  {'up_time': 672.7385516166687}\n"
     ]
    }
   ],
   "source": [
    "gov_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_record(id):\n",
    "    \"\"\"\n",
    "    This function will become a UDF for Spark. Compare with ``log_record`` in ../Spark-RayUDF.ipynb.\n",
    "    \"\"\"\n",
    "    response = requests.put(f'{address}/log?id={id}', timeout=timeout)\n",
    "    return {'response': response.ok}  # A different return value compared to the other log_record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Data Governance Example with Ray Serve\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_record_udf = udf(lambda id: log_record(id), MapType(StringType(), BooleanType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_records=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [Record(i, f'str: {i}') for i in range(num_records)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(records, ['id', 'data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ray = df.select('id', 'data', log_record_udf('id').alias('logged'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, data: bigint, logged: map<string,boolean>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_ray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------------------+\n",
      "|id     |data|logged            |\n",
      "+-------+----+------------------+\n",
      "|str: 0 |0   |[response -> true]|\n",
      "|str: 1 |1   |[response -> true]|\n",
      "|str: 2 |2   |[response -> true]|\n",
      "|str: 3 |3   |[response -> true]|\n",
      "|str: 4 |4   |[response -> true]|\n",
      "|str: 5 |5   |[response -> true]|\n",
      "|str: 6 |6   |[response -> true]|\n",
      "|str: 7 |7   |[response -> true]|\n",
      "|str: 8 |8   |[response -> true]|\n",
      "|str: 9 |9   |[response -> true]|\n",
      "|str: 10|10  |[response -> true]|\n",
      "|str: 11|11  |[response -> true]|\n",
      "|str: 12|12  |[response -> true]|\n",
      "|str: 13|13  |[response -> true]|\n",
      "|str: 14|14  |[response -> true]|\n",
      "|str: 15|15  |[response -> true]|\n",
      "|str: 16|16  |[response -> true]|\n",
      "|str: 17|17  |[response -> true]|\n",
      "|str: 18|18  |[response -> true]|\n",
      "|str: 19|19  |[response -> true]|\n",
      "|str: 20|20  |[response -> true]|\n",
      "|str: 21|21  |[response -> true]|\n",
      "|str: 22|22  |[response -> true]|\n",
      "|str: 23|23  |[response -> true]|\n",
      "|str: 24|24  |[response -> true]|\n",
      "|str: 25|25  |[response -> true]|\n",
      "|str: 26|26  |[response -> true]|\n",
      "|str: 27|27  |[response -> true]|\n",
      "|str: 28|28  |[response -> true]|\n",
      "|str: 29|29  |[response -> true]|\n",
      "|str: 30|30  |[response -> true]|\n",
      "|str: 31|31  |[response -> true]|\n",
      "|str: 32|32  |[response -> true]|\n",
      "|str: 33|33  |[response -> true]|\n",
      "|str: 34|34  |[response -> true]|\n",
      "|str: 35|35  |[response -> true]|\n",
      "|str: 36|36  |[response -> true]|\n",
      "|str: 37|37  |[response -> true]|\n",
      "|str: 38|38  |[response -> true]|\n",
      "|str: 39|39  |[response -> true]|\n",
      "|str: 40|40  |[response -> true]|\n",
      "|str: 41|41  |[response -> true]|\n",
      "|str: 42|42  |[response -> true]|\n",
      "|str: 43|43  |[response -> true]|\n",
      "|str: 44|44  |[response -> true]|\n",
      "|str: 45|45  |[response -> true]|\n",
      "|str: 46|46  |[response -> true]|\n",
      "|str: 47|47  |[response -> true]|\n",
      "|str: 48|48  |[response -> true]|\n",
      "|str: 49|49  |[response -> true]|\n",
      "+-------+----+------------------+\n",
      "\n",
      "CPU times: user 1.67 ms, sys: 1.69 ms, total: 3.36 ms\n",
      "Wall time: 537 ms\n"
     ]
    }
   ],
   "source": [
    "%time df_ray.show(n=num_records, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:    {'count': 51}\n",
      "ids:      {'ids': ['str: 0', 'str: 0', 'str: 1', 'str: 2', 'str: 3', 'str: 4', 'str: 5', 'str: 18', 'str: 19', 'str: 20', 'str: 21', 'str: 22', 'str: 23', 'str: 24', 'str: 6', 'str: 12', 'str: 25', 'str: 7', 'str: 13', 'str: 26', 'str: 8', 'str: 14', 'str: 27', 'str: 9', 'str: 15', 'str: 28', 'str: 10', 'str: 16', 'str: 29', 'str: 11', 'str: 17', 'str: 30', 'str: 36', 'str: 42', 'str: 31', 'str: 37', 'str: 43', 'str: 32', 'str: 38', 'str: 44', 'str: 33', 'str: 39', 'str: 45', 'str: 34', 'str: 40', 'str: 46', 'str: 35', 'str: 41', 'str: 47', 'str: 48', 'str: 49']}\n",
      "up time:  {'up_time': 1017.429967880249}\n"
     ]
    }
   ],
   "source": [
    "gov_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
